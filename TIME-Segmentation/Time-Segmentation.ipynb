{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkpT6wtkd786"
   },
   "source": [
    "# Time Segmentation \n",
    "\n",
    "IPython Notebook for segmentation of morphological structures imperative for \"Tumor Micro Environemnt (TIME)\" analysis.\n",
    "\n",
    "This Code uses MONAI framework for carrying out the segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLl72MMid0pJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.utils import first\n",
    "from monai.transforms import AddChannel, Compose, LoadImage, RandRotate90, RandSpatialCrop, ScaleIntensity, ToTensor,SplitChanneld,SplitChannel, Lambda,Lambdad,Resized,Resize\n",
    "from monai.losses import DiceLoss,TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import ArrayDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.utils import progress_bar\n",
    "from monai.networks.utils import one_hot\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "HqCaraEzieh3",
    "outputId": "434141a3-4925-45c8-bf46-0a844b455070"
   },
   "outputs": [],
   "source": [
    "npz = 'Data.npz'\n",
    "data = np.load('Data.npz',allow_pickle=True)\n",
    "\n",
    "images = data[\"images\"]  # images in BHW array order\n",
    "segs = data[\"mask\"]  # segmentations in BHW array order\n",
    "\n",
    "# Merging some of the labels for ease \n",
    "segs[segs==2]=1\n",
    "segs[segs==3]=2\n",
    "segs[segs==4]=2\n",
    "segs[segs==5]=3\n",
    "segs[segs==6]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnSoc-rujRjq"
   },
   "source": [
    "- Setup the parameters for model training\n",
    "- We will split our data into a training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvIeP4DGjbkT"
   },
   "outputs": [],
   "source": [
    "random.seed(0) \n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Setting up trainign parameters\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "num_epochs = 600\n",
    "lr = 5e-2\n",
    "numLabels = 3\n",
    "\n",
    "#Randomize the data for training and testing.\n",
    "indices = list(range(images.shape[0]))\n",
    "random.shuffle(indices)\n",
    "case_indices = 100\n",
    "test_index = indices[-case_indices: -1]  # keep the last 6 cases for testing\n",
    "train_index = indices[0:images.shape[0]-case_indices]\n",
    "\n",
    "# divide the images, segmentations, and categories into train/test sets\n",
    "train_images, train_segs = images[train_index,:,:], segs[train_index,:,:]\n",
    "test_images, test_segs = images[test_index,:,:], segs[test_index,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qyUcjrljrIs"
   },
   "source": [
    "We can now create a MONAI data loading object to compose batches during training, and another for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xU6A9TNLfEUu",
    "outputId": "1cc3348e-57b8-4eb4-a964-0b9239afa988"
   },
   "outputs": [],
   "source": [
    "from monai.data import CacheDataset\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandZoomd,\n",
    "    Rand2DElasticd,\n",
    "    RandAffined,\n",
    "    RandGaussianSharpend,\n",
    "    RandGaussianNoised,\n",
    "    Resized,\n",
    "    Resize,\n",
    ")\n",
    "\n",
    "aug_prob = 0.2\n",
    "keys = (\"img\", \"seg\")\n",
    "\n",
    "# use these when interpolating binary segmentations to ensure values are 0 or 1 only\n",
    "zoom_mode = monai.utils.enums.InterpolateMode.NEAREST\n",
    "resize_mode = monai.utils.enums.InterpolateMode.NEAREST\n",
    "elast_mode = monai.utils.enums.GridSampleMode.NEAREST\n",
    "\n",
    "\n",
    "trans = Compose(\n",
    "    [\n",
    "        ScaleIntensityd(keys=(\"img\",)),  # rescale image data to range [0,1]\n",
    "        AddChanneld(keys=keys),  # add 1-size channel dimension\n",
    "        Resized(keys = keys,spatial_size=(256,256),mode=['bilinear','nearest']),\n",
    "        #RandGaussianNoised(keys=(\"img\",), prob=aug_prob, mean=0.2, std=0.05),\n",
    "        RandRotate90d(keys=keys, prob=aug_prob),\n",
    "        RandFlipd(keys=keys, prob=aug_prob),\n",
    "        RandZoomd(keys=keys, prob=aug_prob,mode=['bilinear','nearest']),\n",
    "        Rand2DElasticd(keys=keys, prob=aug_prob, spacing=10, magnitude_range=(-2, 2),mode=['bilinear','nearest']),\n",
    "        RandAffined(keys=keys, prob=aug_prob,padding_mode = 'zeros',shear_range = 0.2,rotate_range=20, translate_range=16, mode=['bilinear','nearest']),\n",
    "        #RandGaussianSharpend(keys=(\"img\",),sigma1_x = (0.05,0.1),sigma1_y = (0.05,0.1),sigma2_x = (0.1,0.2),sigma2_y = (0.1,0.2), alpha = (10.0,30.0),prob = aug_prob),\n",
    "        ToTensord(keys=keys),  # convert to tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "data = [\n",
    "    {\"img\": train_images[i], \"seg\": train_segs[i]} for i in range(len(train_images))\n",
    "]\n",
    "\n",
    "ds = CacheDataset(data, trans)\n",
    "loader = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_image_trans = Compose([ScaleIntensity(), AddChannel(),Resize(spatial_size=(256,256),mode='bilinear'), ToTensor(),])\n",
    "\n",
    "val_seg_trans = Compose([AddChannel(),Resize(spatial_size=(256,256),mode='nearest'), ToTensor()])\n",
    "\n",
    "\n",
    "val_ds = ArrayDataset(test_images, val_image_trans, test_segs, val_seg_trans)\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    drop_last = False,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = first(loader)\n",
    "im1 = batch[\"img\"]\n",
    "seg1 = batch[\"seg\"]\n",
    "\n",
    "print(seg1.unique())\n",
    "plt.imshow(seg1[0, 0].numpy())\n",
    "plt.show()\n",
    "plt.imshow(im1[0, 0].numpy())\n",
    "plt.show()\n",
    "plt.imshow(im1[0, 0].numpy()+ 0.25*seg1[0, 0].numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the DICE loss. As our data is **partially labelled**, the Dice loss that we use **ignores the unlabelled pixels (we call them background pixels) during loss calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from monai.networks import one_hot\n",
    "from monai.utils import LossReduction, Weight\n",
    "\n",
    "\n",
    "class DiceLoss_ignoreBack(_Loss):\n",
    "    \"\"\"\n",
    "    Compute average Dice loss between two tensors. It can support both multi-classes and multi-labels tasks.\n",
    "    Input logits `input` (BNHW[D] where N is number of classes) is compared with ground truth `target` (BNHW[D]).\n",
    "    Axis N of `input` is expected to have logit predictions for each class rather than being image channels,\n",
    "    while the same axis of `target` can be 1 or N (one-hot format). The `smooth` parameter is a value added to the\n",
    "    intersection and union components of the inter-over-union calculation to smooth results and prevent divide by 0,\n",
    "    this value should be small. The `include_background` class attribute can be set to False for an instance of\n",
    "    DiceLoss to exclude the first category (channel index 0) which is by convention assumed to be background.\n",
    "    If the non-background segmentations are small compared to the total image size they can get overwhelmed by\n",
    "    the signal from the background so excluding it in such cases helps convergence.\n",
    "\n",
    "    Milletari, F. et. al. (2016) V-Net: Fully Convolutional Neural Networks forVolumetric Medical Image Segmentation, 3DV, 2016.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        include_background: bool = True,\n",
    "        to_onehot_y: bool = False,\n",
    "        sigmoid: bool = False,\n",
    "        softmax: bool = False,\n",
    "        other_act: Optional[Callable] = None,\n",
    "        squared_pred: bool = False,\n",
    "        jaccard: bool = False,\n",
    "        reduction: Union[LossReduction, str] = LossReduction.MEAN,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            include_background: if False channel index 0 (background category) is excluded from the calculation.\n",
    "            to_onehot_y: whether to convert `y` into the one-hot format. Defaults to False.\n",
    "            sigmoid: if True, apply a sigmoid function to the prediction.\n",
    "            softmax: if True, apply a softmax function to the prediction.\n",
    "            other_act: if don't want to use `sigmoid` or `softmax`, use other callable function to execute\n",
    "                other activation layers, Defaults to ``None``. for example:\n",
    "                `other_act = torch.tanh`.\n",
    "            squared_pred: use squared versions of targets and predictions in the denominator or not.\n",
    "            jaccard: compute Jaccard Index (soft IoU) instead of dice or not.\n",
    "            reduction: {``\"none\"``, ``\"mean\"``, ``\"sum\"``}\n",
    "                Specifies the reduction to apply to the output. Defaults to ``\"mean\"``.\n",
    "\n",
    "                - ``\"none\"``: no reduction will be applied.\n",
    "                - ``\"mean\"``: the sum of the output will be divided by the number of elements in the output.\n",
    "                - ``\"sum\"``: the output will be summed.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: When ``other_act`` is not an ``Optional[Callable]``.\n",
    "            ValueError: When more than 1 of [``sigmoid=True``, ``softmax=True``, ``other_act is not None``].\n",
    "                Incompatible values.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(reduction=LossReduction(reduction).value)\n",
    "        if other_act is not None and not callable(other_act):\n",
    "            raise TypeError(f\"other_act must be None or callable but is {type(other_act).__name__}.\")\n",
    "        if int(sigmoid) + int(softmax) + int(other_act is not None) > 1:\n",
    "            raise ValueError(\"Incompatible values: more than 1 of [sigmoid=True, softmax=True, other_act is not None].\")\n",
    "        self.include_background = include_background\n",
    "        self.to_onehot_y = to_onehot_y\n",
    "        self.sigmoid = sigmoid\n",
    "        self.softmax = softmax\n",
    "        self.other_act = other_act\n",
    "        self.squared_pred = squared_pred\n",
    "        self.jaccard = jaccard\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor, smooth: float = 1e-5) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: the shape should be BNH[WD].\n",
    "            target: the shape should be BNH[WD].\n",
    "            smooth: a small constant to avoid nan.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: When ``self.reduction`` is not one of [\"mean\", \"sum\", \"none\"].\n",
    "\n",
    "        \"\"\"\n",
    "        if self.sigmoid:\n",
    "            input = torch.sigmoid(input)\n",
    "\n",
    "        n_pred_ch = input.shape[1]\n",
    "        \n",
    "        if self.softmax:\n",
    "            if n_pred_ch == 1:\n",
    "                warnings.warn(\"single channel prediction, `softmax=True` ignored.\")\n",
    "            else:\n",
    "                input = torch.softmax(input, 1)\n",
    "\n",
    "        if self.other_act is not None:\n",
    "            input = self.other_act(input)\n",
    "\n",
    "        if self.to_onehot_y:\n",
    "            if n_pred_ch == 1:\n",
    "                warnings.warn(\"single channel prediction, `to_onehot_y=True` ignored.\")\n",
    "            else:\n",
    "                if not self.include_background:\n",
    "                    target = one_hot(target.permute([1,0,2,3]).view(-1,1), num_classes=n_pred_ch+1)\n",
    "                else:\n",
    "                    target = one_hot(target.permute([1,0,2,3]).view(-1,1), num_classes=n_pred_ch)\n",
    "        \n",
    "        if not self.include_background:\n",
    "            if n_pred_ch == 1:\n",
    "                warnings.warn(\"single channel prediction, `include_background=False` ignored.\")\n",
    "            else:\n",
    "                # if skipping background, removing first channel\n",
    "                mask = (target[:,0].unsqueeze(dim=1))\n",
    "                target = target[:, 1:]                \n",
    "                input = (torch.reshape(input.permute([0,2,3,1]),(-1,n_pred_ch)))*(1-mask)\n",
    "        assert (\n",
    "            target.shape == input.shape\n",
    "        ), f\"ground truth has differing shape ({target.shape}) from input ({input.shape})\"\n",
    "\n",
    "        \n",
    "        # reducing only spatial dimensions (not batch nor channels)\n",
    "        reduce_axis = 0#list(range(2, len(input.shape)))\n",
    "        intersection = torch.sum(target * input, dim=reduce_axis)\n",
    "\n",
    "        if self.squared_pred:\n",
    "            target = torch.pow(target, 2)\n",
    "            input = torch.pow(input, 2)\n",
    "\n",
    "        ground_o = torch.sum(target, dim=reduce_axis)\n",
    "        pred_o = torch.sum(input, dim=reduce_axis)\n",
    "\n",
    "        denominator = ground_o + pred_o\n",
    "\n",
    "        if self.jaccard:\n",
    "            denominator = 2.0 * (denominator - intersection)\n",
    "\n",
    "        f: torch.Tensor = 1.0 - (2.0 * intersection + smooth) / (denominator + smooth)\n",
    "\n",
    "        if self.reduction == LossReduction.MEAN.value:\n",
    "            f = torch.mean(f)  # the batch and channel average\n",
    "        elif self.reduction == LossReduction.SUM.value:\n",
    "            f = torch.sum(f)  # sum over the batch and channel dims\n",
    "        elif self.reduction == LossReduction.NONE.value:\n",
    "            pass  # returns [N, n_classes] losses\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported reduction: {self.reduction}, available options are [\"mean\", \"sum\", \"none\"].')\n",
    "\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-hNZy4qkHji"
   },
   "source": [
    "Define the model. \n",
    "\n",
    "MONAI offers several segmentation model that you can pick and choose among. We used UNET model for this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lM5NapkCj_Mx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # layer 1: convolution, normalization, downsampling\n",
    "            nn.Conv2d(1, 2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            # layer 2\n",
    "            nn.Conv2d(2, 4, 3, 1, 1),\n",
    "            # layer 3\n",
    "            nn.ConvTranspose2d(4, 2, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            # layer 4: output\n",
    "            nn.Conv2d(2, 1, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "#SegNET MODEL\n",
    "net = monai.networks.nets.SegResNet(spatial_dims=2, \n",
    "                                    init_filters=32, \n",
    "                                    in_channels=1, \n",
    "                                    out_channels=2,\n",
    "                                    dropout_prob=0.5, \n",
    "                                    norm_name='group', \n",
    "                                    num_groups=8, \n",
    "                                    use_conv_final=True, \n",
    "                                    blocks_down=(1, 2, 2, 4), \n",
    "                                    blocks_up=(1, 1, 1), upsample_mode='trilinear')\n",
    "# VNET MODEL\n",
    "net = monai.networks.nets.VNet(spatial_dims=2, \n",
    "                               in_channels=1, \n",
    "                               out_channels=3, \n",
    "                               act=('elu', {'inplace': True}), \n",
    "                               dropout_prob=0.5, \n",
    "                               dropout_dim=(2,3))\n",
    "#HighResNET MODEL\n",
    "net = monai.networks.nets.HighResNet(spatial_dims=2, \n",
    "                                    in_channels=1, \n",
    "                                    out_channels=3, \n",
    "                                    norm_type='instance', \n",
    "                                    dropout_prob=0.5)\n",
    "'''\n",
    "#UNET MODEL\n",
    "net = monai.networks.nets.UNet(dimensions = 2, \n",
    "                               in_channels = 1 , \n",
    "                               out_channels = 3, \n",
    "                               channels = [32,64,128,256,512], \n",
    "                               strides = [1,2,2,2,1], \n",
    "                               kernel_size=3, \n",
    "                               up_kernel_size=3, \n",
    "                               num_res_units=2, \n",
    "                               act='PRELU', \n",
    "                               norm='INSTANCE', \n",
    "                               dropout=0.2)\n",
    "\n",
    "m = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See a summary of the model.\n",
    "from torchsummary import summary\n",
    "summary(net.to(device),(1,256,256))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Di-LUDgO3k5r"
   },
   "source": [
    "Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7dSiOsbmkrbn"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from monai.optimizers import Novograd\n",
    "\n",
    "#Choice among different optimizers\n",
    "#opt = Novograd(net.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2, grad_averaging=False, amsgrad=False)\n",
    "#opt = torch.optim.Adam(net.parameters(), lr)\n",
    "opt = torch.optim.SGD(net.parameters(),lr,momentum =0.9, weight_decay = 0.01,nesterov=True)\n",
    "\n",
    "#Choise different lost functions.\n",
    "#loss = TverskyLoss(softmax=False, to_onehot_y = True,alpha = 0.25,beta = 0.75,include_background=False,reduction=\"mean\")\n",
    "loss = DiceLoss_ignoreBack(softmax=False, to_onehot_y = True,include_background=False,reduction=\"mean\")\n",
    "\n",
    "#Choice among different Metrics\n",
    "#metric = DiceMetric(include_background=False, to_onehot_y=True, reduction=\"mean\")\n",
    "metric = DiceMetric(include_background=True, to_onehot_y=False, reduction=\"mean\")\n",
    "\n",
    "scheduler = CosineAnnealingLR(opt, (num_epochs), eta_min=lr/1000.)\n",
    "\n",
    "\n",
    "step_losses = []\n",
    "epoch_metrics = []\n",
    "total_step = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    \n",
    "    metric_train = []\n",
    "    batchLoss = 0\n",
    "    numBatch = 0\n",
    "    # train network with training images\n",
    "    for batch in loader:\n",
    "        bimages = batch[\"img\"].to(device)\n",
    "        bsegs = batch[\"seg\"].to(device)\n",
    "        #bsegs = one_hot(batch[\"seg\"],num_classes=4).to(device)\n",
    "        #bimages = bimages.to(device)\n",
    "        #bsegs = bsegs.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        prediction = m(net(bimages))\n",
    "        loss_val = loss(prediction, bsegs)        \n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "\n",
    "        step_losses.append((total_step, loss_val.item()))\n",
    "        total_step += 1\n",
    "        numBatch += 1\n",
    "        batchLoss = batchLoss+loss_val.item()\n",
    "        GT = one_hot(bsegs,num_classes=numLabels+1)\n",
    "        mask = GT[:,0,:,:].unsqueeze(dim=1)\n",
    "        GT = GT[:,1:,:,:]\n",
    "        train_metric = metric(prediction*(1-mask), GT)\n",
    "        metric_train.append(train_metric.item())\n",
    "\n",
    "    net.eval()\n",
    "    metric_vals = []\n",
    "    # test our network using the validation dataset\n",
    "    with torch.no_grad():\n",
    "        for bimages, bsegs in val_loader:\n",
    "            bimages = bimages.to(device)\n",
    "            bsegs = bsegs.to(device)\n",
    "            #bsegs = one_hot(bsegs,num_classes=4).to(device)\n",
    "\n",
    "            prediction = m(net(bimages))\n",
    "            GT = one_hot(bsegs,num_classes=numLabels+1)\n",
    "            mask = GT[:,0,:,:].unsqueeze(dim=1)\n",
    "            GT = GT[:,1:,:,:]\n",
    "            pred_metric = metric(prediction*(1-mask), GT)\n",
    "            metric_vals.append(pred_metric.item())\n",
    "\n",
    "    epoch_metrics.append((total_step, np.average(metric_vals)))\n",
    "    progress_bar(epoch + 1, num_epochs, f\"Validation Metric: {epoch_metrics[-1][1]:.3}\")\n",
    "    scheduler.step()\n",
    "    if epoch%10 == 0:\n",
    "\n",
    "        print('\\n Batch Loss is: %s and Training Metric is: %s '%(batchLoss/numBatch,np.average(metric_train)))\n",
    "        print('Current Learning rate: %s '%(np.str(scheduler.get_lr())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'TimeSeg_Unet_B64.pth')\n",
    "#torch.save(model.state_dict(), 'TimeSeg_Unet_B64.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE PORTION OF THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Saving Routine\n",
    "def saveSeg(img,pred,fname):\n",
    "    im = Image.fromarray(np.repeat(np.expand_dims(np.uint8(img.squeeze().cpu().numpy()*255),axis=2),3,axis =2))\n",
    "    im1 = pred.squeeze().cpu().numpy()>0.5\n",
    "    im1 = Image.fromarray(np.uint8(np.transpose(im1,(1,2,0))*255))\n",
    "    alphaBlended1 = Image.blend(im,im1, alpha=1)\n",
    "    alphaBlended1.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference Code\n",
    "net = torch.load('TimeSeg_Unet_B64.pth')\n",
    "net.to(device)\n",
    "numLabels = 3\n",
    "metric = DiceMetric(include_background=True, to_onehot_y=False, reduction=\"mean\")\n",
    "m = nn.Softmax(dim=1)\n",
    "net.eval()\n",
    "metric_vals1 = []\n",
    "metric_vals2 = []\n",
    "metric_vals3 = []\n",
    "# test our network using the validation dataset\n",
    "counter = []\n",
    "predictionCount = 0\n",
    "with torch.no_grad():\n",
    "    for bimages1, bsegs1 in val_loader:\n",
    "        bimages1 = bimages1.to(device)\n",
    "        bsegs1 = bsegs1.to(device)\n",
    "        #bsegs = one_hot(bsegs,num_classes=4).to(device)\n",
    "\n",
    "        prediction = m(net(bimages1))\n",
    "        GT = one_hot(bsegs1,num_classes=numLabels+1)\n",
    "        mask = GT[:,0,:,:].unsqueeze(dim=1)\n",
    "        \n",
    "        for i in range(prediction.shape[0]):\n",
    "            fname = (\"./Labels_v5/Res_%.5d.bmp\"% predictionCount)\n",
    "            predictionCount +=1\n",
    "            saveSeg(bimages1[i,0,:,:],prediction[i,:,:,:],fname)\n",
    "           \n",
    "        pred_metric = metric(prediction[:,0,:,:]*(1-torch.squeeze(mask)), GT[:,1,:,:])\n",
    "        metric_vals1.append(pred_metric.item())\n",
    "        pred_metric = metric(prediction[:,1,:,:]*(1-torch.squeeze(mask)), GT[:,2,:,:])\n",
    "        metric_vals2.append(pred_metric.item())\n",
    "        pred_metric = metric(prediction[:,2,:,:]*(1-torch.squeeze(mask)), GT[:,3,:,:])\n",
    "        metric_vals3.append(pred_metric.item())\n",
    "        counter.append(prediction.shape[0])\n",
    "\n",
    "print(np.sum(np.array(counter)*np.array(metric_vals1))/np.sum(np.array(counter)))\n",
    "print(np.sum(np.array(counter)*np.array(metric_vals2))/np.sum(np.array(counter)))\n",
    "print(np.sum(np.array(counter)*np.array(metric_vals3))/np.sum(np.array(counter)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MONAI_Segment_Exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
